<!DOCTYPE html>
<html lang='en'><head>
  <title>PhD Thesis - Aurélien Appriou</title>
  <link rel='canonical' href='/phd_thesis/' />
  <meta charset='utf-8'>
  <meta name='viewport' content='width=device-width, initial-scale=1' />
  <meta name='description' content='' />
  <meta name='theme-color' content='#FD3519' />
  

  <meta name="generator" content="Hugo 0.72.0" />

  





<link rel="stylesheet" href="/sass/style.min.cf2eeff825d4dbc673ce0b82d270d9fc32d34973a7d5cd079e0dcf4fe3e77515.css" integrity="sha256-zy7v&#43;CXU28ZzzguC0nDZ/DLTSXOn1c0Hng3PT&#43;PndRU=" media="screen">
<link rel="stylesheet" href="/syntax.min.css" integrity="" media="screen">

  <meta property="og:title" content="PhD Thesis" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="/phd_thesis/" />
<meta property="og:image" content="/images/sample.jpg" />


  <meta itemprop="name" content="PhD Thesis">
<meta itemprop="description" content="">
</head>
<body>

  <header style="background-image:linear-gradient(
      rgba(0,0,0,0.4),rgba(0,0,0,0.4)
    ),url(&#39;images/moi_SD.png&#39;)">

  <div class="intro">
    <div class="logo-container">
      <a href="/">
        <img src='/images/profile_square.png' alt="Profile Curiosity" class="rounded-logo">
      </a>
    </div>
    <h2>Hi, I'm Aurélien</h2>
    <h3>PhD candidate in computer science</h3>
    <div class="menu">
      

        <p>
            <a href="/phd_thesis/">
                PhD Thesis
            </a>
        </p>

        <p>
            <a href="/post/">
                Projects
            </a>
        </p>

        <p>
            <a href="/publications/">
                Publications
            </a>
        </p>

        <p>
            <a href="https://scholar.google.com/citations?user=uFLdS3IAAAAJ&amp;hl=en">
                Google Scholar
            </a>
        </p>

        <p>
            <a href="/files/resume_appriou.pdf">
                Resume
            </a>
        </p>

      
        
        <p>
            <a href="mailto:aurelien%20[dot]%20appriou%20[at]%20inria%20[dot]%20fr" target="_blank" rel="external">
                
            </a>
        </p>
      
    </div>

  </div>

  <div class="socials">
      
  
    <a href="https://gitlab.com/" class="social-link" target="_blank" rel="noopener" ><div class="icon">
  <svg width="35px" height="35px" viewBox="0 0 115 115" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img">
  
  <path d="M23.76 5.544c-.693-1.991-3.512-1.991-4.228 0L6.892 44.653h29.532c-.022 0-12.663-39.11-12.663-39.11zM.426 64.34c-.582 1.79.067 3.782 1.589 4.923l55.464 41.167-50.61-65.778L.426 64.34zm35.977-19.688L57.5 110.43l21.098-65.778H36.402zm78.173 19.688l-6.444-19.688L57.5 110.43l55.464-41.167a4.475 4.475 0 0 0 1.61-4.923zM95.468 5.544c-.694-1.991-3.513-1.991-4.229 0L78.576 44.653h29.533L95.468 5.543z" />
  
  </svg>
</div>
</a>
  

  
    <a href="https://www.linkedin.com/in/" class="social-link" target="_blank" rel="noopener" ><div class="icon">
  <svg width="35px" height="35px" viewBox="0 0 115 115" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img">
  
  <path d="M106.786 0H8.189C3.67 0 0 3.722 0 8.291v98.418C0 111.278 3.67 115 8.189 115h98.597c4.518 0 8.214-3.722 8.214-8.291V8.29C115 3.722 111.304 0 106.786 0zm-72.03 98.571H17.713V43.69h17.07V98.57h-.025zm-8.522-62.377c-5.467 0-9.882-4.44-9.882-9.883 0-5.442 4.415-9.882 9.882-9.882 5.442 0 9.883 4.44 9.883 9.882a9.87 9.87 0 0 1-9.883 9.883zm72.414 62.377H81.604V71.875c0-6.366-.129-14.555-8.856-14.555-8.882 0-10.242 6.931-10.242 14.093V98.57H45.46V43.69h16.352v7.495h.23c2.285-4.312 7.855-8.856 16.147-8.856 17.25 0 20.458 11.372 20.458 26.158V98.57z"/>
  
  </svg>
</div>
</a>
  

  
    <a href="https://twitter.com/" class="social-link" target="_blank" rel="noopener" ><div class="icon">
  <svg width="35px" height="35px" viewBox="0 0 115 115" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img">
  
  <path d="M102.679 0H12.32C5.52 0 0 5.519 0 12.321v90.358C0 109.48 5.519 115 12.321 115h90.358c6.802 0 12.321-5.519 12.321-12.321V12.32C115 5.52 109.481 0 102.679 0zM90.126 40.763c.051.72.051 1.464.051 2.182 0 22.256-16.942 47.9-47.9 47.9-9.548 0-18.404-2.772-25.848-7.547 1.36.154 2.67.205 4.055.205 7.881 0 15.12-2.67 20.895-7.187-7.392-.154-13.604-5.006-15.735-11.68 2.593.385 4.929.385 7.598-.308a16.837 16.837 0 0 1-13.476-16.531v-.205a16.824 16.824 0 0 0 7.598 2.13 16.8 16.8 0 0 1-7.496-14.016c0-3.131.822-6.006 2.285-8.496a47.803 47.803 0 0 0 34.705 17.61c-2.387-11.424 6.161-20.69 16.429-20.69 4.851 0 9.215 2.027 12.296 5.313a32.99 32.99 0 0 0 10.678-4.056 16.792 16.792 0 0 1-7.393 9.267c3.389-.36 6.674-1.31 9.703-2.618a35.437 35.437 0 0 1-8.445 8.727z"/>
  
  </svg>
</div>
</a>
  

  </div>

</header>

  <div class="content-wrapper">
    
      <div class="breadcrumb">
  



<span >
  <a href="/">Aurélien Appriou</a>
   / 
</span>


<span  class="active">
  <a href="/phd_thesis/">PhD Thesis</a>
  
</span>

</div>

    
    <main id="content" class="phd_thesis">

  <h1 id="title"> PhD Thesis</h1>
  <p><h3 id="estimating-learning-related-mental-states-from-electroencephalographic-and-physiological-signals">Estimating learning-related mental states from electroencephalographic and physiological signals</h3>
<hr>
<p>Studying human learning is crucial: how can humans learn and what are their motivations to keep building-up knowledge? Every human is permanently learning to adapt to his environment and current generations now have to learn to use rapidly evolving technologies. As part of emerging technologies, research on brain-computer interfaces (BCIs) has become more democratic in recent decades, and experiments using electroencephalography (EEG)-based BCIs dramatically increased. This technology enables direct transfer of information from the human brain to a machine via brain signals, and can notably enable people with severe motor impairments to send commands to a wheelchair, e.g., by imagining left or right hand movements to make the wheelchair turn left or right. Such BCIs are called active BCIs since users are actively sending commands to the system, here a wheelchair, by performing mental imagery. However, current training protocols do not enable 10 to 30% of persons to acquire the skills required to use Motor Imagery-based BCIs (MI-BCIs). The lack of robustness of BCIs limits the development of the technology outside of research laboratories. However, another type of BCIs recently proved particularly promising: passive BCIs. Such BCIs are not used to directly control an application, but to monitor in real-time users’ mental states, e.g., mental workload or attention, in order to adapt an application accordingly.</p>
<p>In one part of my thesis work, we worked on estimating learning-related mental states such as ognitive workload, curiosity, attention, fatigue or frustration from EEG and/or bio signals using passive BCIs, in order to understand individual users’ capabilities and motivations to learn. Being able to measure such mental states with EEG and/or bio signals would allow to adapt training approaches and tools to different learners, including the MI-BCIs learners. In a first project, we explored recent machine learning algorithms that have shown to be promising for MI-BCIs, but that have never been tested on mental states estimation, proposed new variants of them, and benchmarked them with classical methods to estimate both mental workload and affective states (Valence/Arousal) from oscillatory-based EEG signals. In a second project, we are currently exploring signal processing and machine learning that have proved to be efficient on MI-BCIs, and benchmarked them with classical methods to estimate both mental workload and curiosity from Evoked Response Potential (ERP)-based EEG signals. In a third project, we ran an experiment in which we used EEG, Heart Rate (HR), breathing and Electrodermal Activity (EDA) signals to measure the neurophysiological activity of participants as they were induced into states of curiosity, using trivia question and answer chains. Finally, a last project is underway, in which we will run an experiment in order to assess participants’ cognitive load during MI-BCI training using EEG signals.</p>
<p>In another part of my thesis work, I implemented a Python library (BioPyC) to easily compare and benchmark both Signal Processing algorithms and Machine Learning algorithms for offline EEG and bio signals decoding. Based on an intuitive and well-guided graphical interface, four main modules allow the user to follow the standard steps of the BCI process without any programming skills 1) reading different neurophysiological signal data formats 2) filtering and representing EEG and biosignals 3) classifying them 4) visualizing and performing statistical tests on the results.</p>
</p>
  <ul id="list">
    
  </ul>

    </main>
  </div>
  <footer>
    <div class="footer-wrapper">
      <p>For more information, contact me at: aurelien [dot] appriou [at] inria [dot] fr</p>
    </div>
  </footer>
  <link href="https://fonts.googleapis.com/css?family=Montserrat:500,600|Raleway:400,400i,600" rel="stylesheet">
  
</body>
</html>